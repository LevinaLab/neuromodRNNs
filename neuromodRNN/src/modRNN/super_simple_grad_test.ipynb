{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tasks\n",
    "import models\n",
    "import models_2\n",
    "import learning_rules\n",
    "import learning_utils\n",
    "from jax import random, numpy as jnp\n",
    "from optax import losses\n",
    "import jax\n",
    "from typing import (\n",
    "  Any,\n",
    "  Callable,\n",
    "  Dict,\n",
    "  List,\n",
    "  Optional,\n",
    "  Sequence,\n",
    "  Tuple,\n",
    "  Iterable  \n",
    " )\n",
    "from flax.typing import (PRNGKey)\n",
    "import optax\n",
    "from flax.training import train_state, orbax_utils\n",
    "Array = jnp.ndarray\n",
    "TrainState = train_state.TrainState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = models.LSSN(n_ALIF=0, n_LIF=2, n_out=1, local_connectivity=False)\n",
    "model_2 = models_2.LSSN(n_ALIF=0, n_LIF=2, n_out=1, local_connectivity=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization_loss(logits, labels, z, c_reg, f_target, trial_length):\n",
    "    \n",
    "  if labels.ndim==2: # calling labels what normally people call targets in regression tasks\n",
    "      labels = jnp.expand_dims(labels, axis=-1) # this is necessary because target labels might have only (n_batch, n_t) and predictions (n_batch, n_t, n_out=1)\n",
    "\n",
    "  task_loss = jnp.sum(0.5 * losses.squared_error(targets=labels, predictions=logits)) # mean over batches and time \n",
    "  jax.debug.print(\"loss{}\",task_loss)\n",
    "  return task_loss \n",
    "optimization_loss_fn = optimization_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = jnp.expand_dims(jnp.array([[1,1], [0,0], [1,0], [0,1]]), axis=1)\n",
    "inputs.shape\n",
    "labels = jnp.expand_dims(jnp.array([1, 2, 0, 3]), axis=1)\n",
    "labels.shape\n",
    "trial_len = jnp.array([1,1,1,1])\n",
    "batch = {\"input\":inputs, \"label\":labels, \"trial_duration\":trial_len}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_params(rng, model, input_shape):\n",
    "  \"\"\"Returns randomly initialized parameters, eligibility parameters and connectivity mask.\"\"\"\n",
    "  dummy_x = jnp.ones(input_shape)\n",
    "  variables = model.init(rng, dummy_x)\n",
    "  return variables['params'], variables['eligibility params'], variables['spatial params']\n",
    "    \n",
    "\n",
    "def get_init_eligibility_carries(rng, model, input_shape):\n",
    "  \"\"\"Returns randomly initialized carries. In the default mode, they are all initialized as zeros arrays\"\"\"\n",
    "  return model.initialize_eligibility_carry(rng, input_shape)\n",
    "\n",
    "def get_init_error_grid(rng, model, input_shape):\n",
    "   \"\"\"Return initial error grid initialized as zeros\"\"\"\n",
    "   return model.initialize_grid(rng=rng, input_shape=input_shape)\n",
    "\n",
    "# Create a custom TrainState to include both params and other variable collections\n",
    "class TrainStateEProp(TrainState):\n",
    "  \"\"\" Personalized TrainState for e-prop with local connectivity \"\"\"\n",
    "  eligibility_params: Dict[str, Array]\n",
    "  spatial_params: Dict[str, Array]\n",
    "  init_eligibility_carries: Dict[str, Array]\n",
    "  init_error_grid: Array\n",
    "  \n",
    "def create_train_state(rng:PRNGKey, learning_rate:float, model, input_shape:Tuple[int,...])->train_state.TrainState:\n",
    "  \"\"\"Create initial training state.\"\"\"\n",
    "  key1, key2, key3 = random.split(rng, 3)\n",
    "  params, eligibility_params, spatial_params = get_initial_params(key1, model, input_shape)\n",
    "  init_eligibility_carries = get_init_eligibility_carries(key2, model, input_shape)\n",
    "  init_error_grid = get_init_error_grid(key3, model, input_shape)\n",
    "\n",
    "  tx = optax.adam(learning_rate=learning_rate)\n",
    "\n",
    "  state = TrainStateEProp.create(apply_fn=model.apply, params=params, tx=tx, \n",
    "                                  eligibility_params=eligibility_params,\n",
    "                                  spatial_params = spatial_params,\n",
    "                                  init_eligibility_carries=init_eligibility_carries,                                  \n",
    "                                  init_error_grid=init_error_grid\n",
    "                                  )\n",
    "  return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_1 = create_train_state(random.key(0), learning_rate=0.01, model=model_1, input_shape=(4,2))\n",
    "state_2 = create_train_state(random.key(0), learning_rate=0.01, model=model_2, input_shape=(4,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALIFCell_0': {'input_weights': Array([[1., 1.],\n",
       "         [1., 1.]], dtype=float32),\n",
       "  'recurrent_weights': Array([[1., 0.],\n",
       "         [0., 1.]], dtype=float32)},\n",
       " 'ReadOut_0': {'readout_weights': Array([[1.],\n",
       "         [1.]], dtype=float32)}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_1.params[\"ALIFCell_0\"][\"input_weights\"] = jnp.array([[1.,1.], [1.,1.]])\n",
    "state_1.params[\"ALIFCell_0\"][\"recurrent_weights\"] = jnp.array([[1.,0.], [0.,1.]])\n",
    "state_1.params[\"ReadOut_0\"][\"readout_weights\"] = jnp.array([[1.], [1.]])\n",
    "state_1.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALIFCell_0': {'M': Array([[1., 1.],\n",
       "         [1., 1.]], dtype=float32),\n",
       "  'cells_loc': Array([[2, 3],\n",
       "         [6, 0]], dtype=int32),\n",
       "  'diff_K': Array([[[[0., 0., 0.],\n",
       "           [0., 0., 0.],\n",
       "           [0., 0., 0.]]]], dtype=float32)}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_1.spatial_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LS_avail = 1\n",
    "c_reg =0\n",
    "f_target = 10\n",
    "optimization_loss_fn = optimization_loss\n",
    "task = \"regression\"\n",
    "local_connectivity = True\n",
    "learning_rule = \"e_prop_hardcoded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss5.0\n"
     ]
    }
   ],
   "source": [
    "logits_1, grads_1 = learning_rules.autodiff_grads(batch=batch,state=state_1, optimization_loss_fn=optimization_loss_fn,\n",
    "                                                  LS_avail= LS_avail, c_reg=c_reg, f_target=f_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[2.]],\n",
       "\n",
       "       [[0.]],\n",
       "\n",
       "       [[2.]],\n",
       "\n",
       "       [[2.]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALIFCell_0': {'input_weights': Array([[ 0.33333337,  0.33333337],\n",
       "         [-0.16666669, -0.16666669]], dtype=float32),\n",
       "  'recurrent_weights': Array([[0., 0.],\n",
       "         [0., 0.]], dtype=float32)},\n",
       " 'ReadOut_0': {'readout_weights': Array([[2.],\n",
       "         [2.]], dtype=float32)}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_batch: [[[2.]]\n",
      "\n",
      " [[0.]]\n",
      "\n",
      " [[2.]]\n",
      "\n",
      " [[2.]]]\n",
      "crop_trace: [[[1. 1.]\n",
      "  [0. 0.]\n",
      "  [1. 1.]\n",
      "  [1. 1.]]]\n",
      "err: [[[ 1.]]\n",
      "\n",
      " [[-2.]]\n",
      "\n",
      " [[ 2.]]\n",
      "\n",
      " [[-1.]]]\n"
     ]
    }
   ],
   "source": [
    "logits_hard_1,hard_grads_1 = learning_rules.compute_grads(batch=batch, state=state_1,optimization_loss_fn=optimization_loss_fn,\n",
    "                                                  LS_avail=LS_avail, local_connectivity=local_connectivity, \n",
    "                                                  f_target=f_target, c_reg=c_reg, learning_rule=learning_rule, task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALIFCell_0': {'input_weights': Array([[0., 0.],\n",
       "         [0., 0.]], dtype=float32),\n",
       "  'recurrent_weights': Array([[0., 0.],\n",
       "         [0., 0.]], dtype=float32)},\n",
       " 'ReadOut_0': {'readout_weights': Array([[2.],\n",
       "         [2.]], dtype=float32)}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_grads_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modRNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
